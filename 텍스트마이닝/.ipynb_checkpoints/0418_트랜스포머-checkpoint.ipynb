{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8140c39",
   "metadata": {},
   "source": [
    "# 트랜스포머(Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e16908",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/31379/transformer5_final_final.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq의 단점을 개선하면서도 여전히 인코더-디코더 구조를 유지\n",
    "\n",
    "\n",
    "기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어져 있었습니다. 여기서 인코더는 입력 시퀀스를 하나의 벡터 표현으로 압축하고, \n",
    "디코더는 이 벡터 표현을 통해서 출력 시퀀스를 만들어냈습니다. 하지만 이러한 구조는 인코더가 입력 시퀀스를 하나의 벡터로 압축하는 \n",
    "과정에서 입력 시퀀스의 정보가 일부 손실된다는 단점이 있었고, 이를 보정하기 위해 어텐션이 사용\n",
    "\n",
    "어텐션을 RNN의 보정을 위한 용도로서 사용하는 것이 아니라 어텐션만으로 인코더와 디코더를 만들어보면 어떨까\n",
    "\n",
    "\n",
    "트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있습니다. \n",
    "트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용하는데, \n",
    "이를 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d633cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bc141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bfcfe30",
   "metadata": {},
   "source": [
    "## 어텐션 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d460314",
   "metadata": {},
   "source": [
    "### 셀프 어텐션의 의미와 이점\n",
    " 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로 대명사가 가르키는 대상을 찾기 수월하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394fa4b2",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c84bb",
   "metadata": {},
   "source": [
    "#### seq2seq에서 어텐션을 사용할 경우의 Q, K, V의 정의\n",
    "* Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "* K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "* V = Values : 모든 시점의 인코더 셀의 은닉 상태들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T05:36:44.604239Z",
     "start_time": "2022-04-18T05:36:44.585290Z"
    }
   },
   "source": [
    "#### 트랜스포머의 셀프어텐션\n",
    "* Q : 입력 문장의 모든 단어 벡터들\n",
    "* K : 입력 문장의 모든 단어 벡터들\n",
    "* V : 입력 문장의 모든 단어 벡터들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf994674",
   "metadata": {},
   "source": [
    "### Q,K,V 벡터 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149793b",
   "metadata": {},
   "source": [
    "![](https://wikidocs.net/images/page/31379/transformer11.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90babd40",
   "metadata": {},
   "source": [
    "기존의 벡터로부터 더 작은 벡터는 가중치 행렬을 곱하므로서 완성됩니다. 각 가중치 행렬은 d_model × (d_model/num_heads)\n",
    "의 크기를 가집니다. 이 가중치 행렬은 훈련 과정에서 학습됩니다. 즉, 논문과 같이 d_model=512이고 \n",
    "num_heads=8 이라면, 각 벡터에 3개의 서로 다른 가중치 행렬을 곱하고 64의 크기를 가지는 Q, K, V 벡터를 얻어냅니다. \n",
    "위의 그림은 단어 벡터 중 student 벡터로부터 Q, K, V 벡터를 얻어내는 모습을 보여줍니다. \n",
    "모든 단어 벡터에 위와 같은 과정을 거치면 I, am, a, student는 각각의 Q, K, V 벡터를 얻습니다\n",
    "(d_model: 인코더의 초기입력차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af02d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0d005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4fe94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
